{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Path to the folder containing the ground truth images\n",
    "data_dir = r'C:\\Users\\Babak\\Desktop\\Automated_Dural_sack_measurement\\05_Final_Ground_Truth_Data\\Label_Images'\n",
    "\n",
    "# Path to the folder where the binary masks for the TS region will be saved\n",
    "output_dir = r'C:\\Users\\Babak\\Desktop\\Automated_Dural_sack_measurement\\Output_TS'\n",
    "\n",
    "# Define the color range to extract (in this case, the TS color)\n",
    "lower_range = np.array([150, 150, 150])\n",
    "upper_range = np.array([150, 150, 150])\n",
    "\n",
    "# HEX and RGB values for the TS region\n",
    "TS_HEX = '#969696' # got for example through https://imagecolorpicker.com/\n",
    "TS_RGB = (150, 150, 150) # got for example through https://imagecolorpicker.com/\n",
    "\n",
    "# Loop through each image in the ground truth folder\n",
    "for filename in os.listdir(data_dir):\n",
    "    # Load the image\n",
    "    img = cv2.imread(os.path.join(data_dir, filename))\n",
    "\n",
    "    # Create a binary mask with only the TS pixels\n",
    "    mask = cv2.inRange(img, lower_range, upper_range)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    ts_img = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "\n",
    "    # Save the binary mask in the output folder with the same filename\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    cv2.imwrite(output_path, ts_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.layers import multiply\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import add, Activation\n",
    "from tensorflow.keras.layers import BatchNormalization, add, Activation, concatenate\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess(img):\n",
    "    img = cv2.resize(img, (320, 320))\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def load_data(data_dir, label_dir):\n",
    "    x_train, y_train = [], []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.endswith('.png') and filename.startswith('T1'):\n",
    "            # Load the image\n",
    "            img = cv2.imread(os.path.join(data_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Load the corresponding label image\n",
    "            label_filename = filename.replace('T1', 'L1')\n",
    "            label_img = cv2.imread(os.path.join(label_dir, label_filename), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Preprocess the input and label images\n",
    "            img = preprocess(img)\n",
    "            label_img = preprocess(label_img)\n",
    "\n",
    "            # Normalize the label image\n",
    "            label_img = np.where(label_img == 150/255, 1.0, 0.0)\n",
    "\n",
    "            # Append the images to the lists\n",
    "            x_train.append(img)\n",
    "            y_train.append(label_img)\n",
    "    \n",
    "    return np.array(x_train), np.array(y_train)\n",
    "\n",
    "# Attention Gate\n",
    "def attention_gate(inp, g, inter_channels):\n",
    "    theta_x = Conv2D(inter_channels, [2, 2], strides=[1, 1], padding='same')(inp)\n",
    "    phi_g = Conv2D(inter_channels, [1, 1], padding='same')(g)\n",
    "    theta_x_upsampled = UpSampling2D(size=(2, 2))(theta_x)  # Upsample theta_x to match the dimensions of phi_g\n",
    "\n",
    "    f = Activation('relu')(add([theta_x_upsampled, phi_g]))\n",
    "    f_pooled = MaxPooling2D((2, 2))(f)  # Adjust the resolution of f to match inp\n",
    "    psi_f = Conv2D(1, [1, 1], activation='sigmoid')(f_pooled)\n",
    "    rate = multiply([inp, psi_f])\n",
    "\n",
    "    return rate\n",
    "\n",
    "\n",
    "\n",
    "def weighted_binary_crossentropy(pos_weight, neg_weight):\n",
    "    def _weighted_binary_crossentropy(y_true, y_pred):\n",
    "        bce = K.binary_crossentropy(y_true, y_pred)\n",
    "        weight_vector = y_true * pos_weight + (1. - y_true) * neg_weight\n",
    "        weighted_bce = weight_vector * bce\n",
    "        return K.mean(weighted_bce)\n",
    "    return _weighted_binary_crossentropy\n",
    "\n",
    "# Set the weights for positive and negative classes\n",
    "pos_weight = 20.0\n",
    "neg_weight = 1.0\n",
    "\n",
    "# U-Net model\n",
    "def unet_model(input_size=(320, 320, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(256, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(256, (3, 3), activation='relu', padding='same')(c4)\n",
    "\n",
    "    u5 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u5 = concatenate([u5, c3])\n",
    "    c5 = Conv2D(128, (3, 3), activation='relu', padding='same')(u5)\n",
    "    c5 = Conv2D(128, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c2])\n",
    "    c6 = Conv2D(64, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(64, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c1])\n",
    "    c7 = Conv2D(32, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(32, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    # Compile the model with the custom loss function\n",
    "    model.compile(optimizer='adam', loss=weighted_binary_crossentropy(pos_weight, neg_weight), metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def attention_unet_model(input_size=(320, 320, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "    c4 = Conv2D(256, (3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv2D(256, (3, 3), activation='relu', padding='same')(c4)\n",
    "\n",
    "    att5 = attention_gate(c4, c3, 128)  # Adding attention gate\n",
    "    u5 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(att5)\n",
    "    c5 = Conv2D(128, (3, 3), activation='relu', padding='same')(u5)\n",
    "    c5 = Conv2D(128, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    att6 = attention_gate(c5, c2, 64)  # Adding attention gate\n",
    "    u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(att6)\n",
    "    u6 = concatenate([u6, c2])\n",
    "    c6 = Conv2D(64, (3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv2D(64, (3, 3), activation='relu', padding='same')(c6)\n",
    "\n",
    "    att7 = attention_gate(c6, c1, 32)  # Adding attention gate\n",
    "    u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(att7)\n",
    "    c7 = Conv2D(32, (3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv2D(32, (3, 3), activation='relu', padding='same')(c7)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c7)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    # Compile the model with the custom loss function\n",
    "    model.compile(optimizer='adam', loss=weighted_binary_crossentropy(pos_weight, neg_weight), metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
    "    '''\n",
    "    2D Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
    "        activation {str} -- activation function (default: {'relu'})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "\n",
    "    if(activation == None):\n",
    "        return x\n",
    "\n",
    "    x = Activation(activation, name=name)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
    "    '''\n",
    "    2D Transposed Convolutional layers\n",
    "    \n",
    "    Arguments:\n",
    "        x {keras layer} -- input layer \n",
    "        filters {int} -- number of filters\n",
    "        num_row {int} -- number of rows in filters\n",
    "        num_col {int} -- number of columns in filters\n",
    "    \n",
    "    Keyword Arguments:\n",
    "        padding {str} -- mode of padding (default: {'same'})\n",
    "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
    "        name {str} -- name of the layer (default: {None})\n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization(axis=3, scale=False)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Adding the MultiResUNet model\n",
    "def MultiResBlock(U, inp, alpha = 1.67):\n",
    "    '''\n",
    "    MultiRes Block\n",
    "    \n",
    "    Arguments:\n",
    "        U {int} -- Number of filters in a corrsponding UNet stage\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "    W = alpha * U\n",
    "\n",
    "    shortcut = inp\n",
    "\n",
    "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
    "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
    "\n",
    "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
    "                        activation='relu', padding='same')\n",
    "\n",
    "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def ResPath(filters, length, inp):\n",
    "    '''\n",
    "    ResPath\n",
    "    \n",
    "    Arguments:\n",
    "        filters {int} -- [description]\n",
    "        length {int} -- length of ResPath\n",
    "        inp {keras layer} -- input layer \n",
    "    \n",
    "    Returns:\n",
    "        [keras layer] -- [output layer]\n",
    "    '''\n",
    "\n",
    "\n",
    "    shortcut = inp\n",
    "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                         activation=None, padding='same')\n",
    "\n",
    "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "    out = add([shortcut, out])\n",
    "    out = Activation('relu')(out)\n",
    "    out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    for i in range(length-1):\n",
    "\n",
    "        shortcut = out\n",
    "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
    "                             activation=None, padding='same')\n",
    "\n",
    "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
    "\n",
    "        out = add([shortcut, out])\n",
    "        out = Activation('relu')(out)\n",
    "        out = BatchNormalization(axis=3)(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "def MultiResUnet(input_size=(320, 320, 1)):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    mresblock1 = MultiResBlock(32, inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
    "    mresblock1 = ResPath(32, 4, mresblock1)\n",
    "\n",
    "    mresblock2 = MultiResBlock(32*2, pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
    "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
    "\n",
    "    mresblock3 = MultiResBlock(32*4, pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
    "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
    "\n",
    "    mresblock4 = MultiResBlock(32*8, pool3)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
    "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
    "\n",
    "    mresblock5 = MultiResBlock(32*16, pool4)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
    "    mresblock6 = MultiResBlock(32*8, up6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
    "    mresblock7 = MultiResBlock(32*4, up7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
    "    mresblock8 = MultiResBlock(32*2, up8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
    "    mresblock9 = MultiResBlock(32, up9)\n",
    "\n",
    "    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "    model.compile(optimizer='adam', loss=weighted_binary_crossentropy(pos_weight, neg_weight), metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "data_dir = r'C:\\Users\\Babak\\Desktop\\Automated_Dural_sack_measurement\\04_Intermediary_Ground_Truth_Data\\T1_Output'\n",
    "label_dir = r'C:\\Users\\Babak\\Desktop\\Automated_Dural_sack_measurement\\Output_TS'\n",
    "\n",
    "x_train, y_train = load_data(data_dir, label_dir)\n",
    "\n",
    "\n",
    "# Define 5-fold cross validation\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store metrics\n",
    "val_loss_per_fold_unet = []\n",
    "val_loss_per_fold_att_unet = []\n",
    "val_loss_per_fold_multi_unet = []\n",
    "\n",
    "# To keep track of the best model\n",
    "best_model_unet = None\n",
    "best_model_att_unet = None\n",
    "best_model_multi_unet = None\n",
    "lowest_val_loss_unet = float('inf')\n",
    "lowest_val_loss_att_unet = float('inf')\n",
    "lowest_val_losses_multi_unet = float('inf')\n",
    "\n",
    "# Define models\n",
    "model_functions = [unet_model, attention_unet_model, MultiResUnet]\n",
    "model_names = ['U-Net', 'Attention U-Net', 'MultiResUNet']\n",
    "best_models = [best_model_unet, best_model_att_unet, best_model_multi_unet]\n",
    "lowest_val_losses = [lowest_val_loss_unet, lowest_val_loss_att_unet, lowest_val_losses_multi_unet]\n",
    "val_losses = [val_loss_per_fold_unet, val_loss_per_fold_att_unet, val_loss_per_fold_multi_unet]\n",
    "\n",
    "# Iterate over both models\n",
    "for i, model_function in enumerate(model_functions):\n",
    "    print('Training model:', model_names[i])\n",
    "\n",
    "    # Reset fold counter for each model\n",
    "    fold_no = 0\n",
    "\n",
    "    # Iterate through each fold\n",
    "    for train, test in kfold.split(x_train, y_train):\n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_no + 1}')\n",
    "\n",
    "        # Create a new model for each fold\n",
    "        model = model_function()\n",
    "\n",
    "        # Fit the model\n",
    "        history = model.fit(\n",
    "            x_train[train], y_train[train],\n",
    "            batch_size=32,\n",
    "            epochs=20,\n",
    "            validation_data=(x_train[test], y_train[test])\n",
    "        )\n",
    "\n",
    "        # Evaluate and store the metrics for each fold\n",
    "        scores = model.evaluate(x_train[test], y_train[test], verbose=0)\n",
    "        print(f'Score for fold {fold_no + 1}: {model.metrics_names[0]} of {scores[0]}')\n",
    "        val_losses[i].append(scores[0])\n",
    "\n",
    "        # Save the model if it has a lower validation loss than the current best model\n",
    "        if scores[0] < lowest_val_losses[i]:\n",
    "            lowest_val_losses[i] = scores[0]\n",
    "            best_models[i] = model\n",
    "\n",
    "        # Increment fold counter\n",
    "        fold_no += 1\n",
    "\n",
    "    # Average metrics\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Loss: {np.mean(val_losses[i])}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "\n",
    "# Save the best models\n",
    "best_models[0].save('unet_dural_sack_new.h5')\n",
    "best_models[1].save('attention_unet_dural_sack_new.h5')\n",
    "best_models[2].save('multiresunet_dural_sack_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Set the pixel size in mm\n",
    "pixel_size_mm = 0.6875  # Adjust this value according to your image resolution\n",
    "\n",
    "# Calculate the dural sack cross-sectional area for each image\n",
    "def calculate_areas(mask, pixel_size):\n",
    "    areas = []\n",
    "    for m in mask:\n",
    "        area = np.sum(m) * pixel_size**2\n",
    "        areas.append(area)\n",
    "    return np.array(areas)\n",
    "\n",
    "model_filenames = [\n",
    "    'unet_dural_sack_new.h5', \n",
    "    'attention_unet_dural_sack_new.h5', \n",
    "    'multiresunet_dural_sack_new.h5'\n",
    "]\n",
    "\n",
    "model_names = [\"U-Net\", \"Attention U-Net\", \"MultiResUNet\"]  # Ensure this list corresponds with the model_filenames list\n",
    "\n",
    "for i, model_filename in enumerate(model_filenames):\n",
    "    # Load the trained model\n",
    "    model = tf.keras.models.load_model(model_filename, custom_objects={'_weighted_binary_crossentropy': weighted_binary_crossentropy(pos_weight, neg_weight)})\n",
    "\n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(x_val)\n",
    "    y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "    # Calculate areas for predicted and ground truth masks\n",
    "    areas_pred = calculate_areas(y_pred_binary, pixel_size_mm)\n",
    "    areas_gt = calculate_areas(y_val, pixel_size_mm)\n",
    "\n",
    "    # Calculate Mean Absolute Error (MAE) and Mean Squared Error (MSE)\n",
    "    mae = mean_absolute_error(areas_gt, areas_pred)\n",
    "    mse = mean_squared_error(areas_gt, areas_pred)\n",
    "    print(f\"Model: {model_names[i]}\")  # Changed to model_names[i]\n",
    "    print(f\"Mean Absolute Error: {mae:.4f} mm²\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f} mm²\")\n",
    "\n",
    "    # Calculate Pearson correlation coefficient\n",
    "    r, p = pearsonr(areas_gt, areas_pred)\n",
    "    print(f\"Pearson correlation coefficient: {r:.4f}\")\n",
    "\n",
    "    # Visualize the results with a scatter plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(areas_gt, areas_pred)\n",
    "    plt.xlabel('Ground truth area (mm²)')\n",
    "    plt.ylabel('Predicted area (mm²)')\n",
    "    plt.title(f'Scatter plot of predicted vs ground truth areas for {model_names[i]}')  # Changed to model_names[i]\n",
    "    plt.plot([min(areas_gt), max(areas_gt)], [min(areas_gt), max(areas_gt)], 'r--', label='Identity line')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Bland-Altman plot\n",
    "    mean_diff = np.mean(areas_pred - areas_gt)\n",
    "    std_diff = np.std(areas_pred - areas_gt)\n",
    "    upper_limit = mean_diff + 1.96 * std_diff\n",
    "    lower_limit = mean_diff - 1.96 * std_diff\n",
    "\n",
    "    print(f\"Mean difference: {mean_diff:.4f} mm²\")\n",
    "    print(f\"Limits of agreement: [{lower_limit:.4f}, {upper_limit:.4f}] mm²\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter((areas_gt + areas_pred) / 2, areas_pred - areas_gt)\n",
    "    plt.axhline(mean_diff, color='red', linestyle='--', label='Mean difference')\n",
    "    plt.axhline(upper_limit, color='blue', linestyle='--', label='Upper limit (1.96 SD)')\n",
    "    plt.axhline(lower_limit, color='blue', linestyle='--', label='Lower limit (1.96 SD)')\n",
    "    plt.xlabel('Mean of ground truth and predicted areas (mm²)')\n",
    "    plt.ylabel('Difference between predicted and ground truth areas (mm²)')\n",
    "    plt.title(f'Bland-Altman plot for {model_names[i]}')  # Changed to model_names[i]\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "pixel_size_mm = 0.6875\n",
    "\n",
    "def calculate_area(mask, pixel_size_mm):\n",
    "    num_pixels = np.sum(mask)\n",
    "    return num_pixels * (pixel_size_mm ** 2)\n",
    "\n",
    "# Load the trained models\n",
    "model_filenames = [\n",
    "    'unet_dural_sack_new.h5', \n",
    "    'attention_unet_dural_sack_new.h5', \n",
    "    'multiresunet_dural_sack_new.h5'\n",
    "]\n",
    "\n",
    "model_names = [\"U-Net\", \"Attention U-Net\", \"MultiResUNet\"]\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE) for each slice for each model and store it in a list\n",
    "mae_per_slice_all_models = []\n",
    "\n",
    "for model_filename in model_filenames:\n",
    "    model = tf.keras.models.load_model(model_filename, custom_objects={'_weighted_binary_crossentropy': weighted_binary_crossentropy(pos_weight, neg_weight)})\n",
    "    y_pred = model.predict(x_val)\n",
    "    y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "    areas_pred = calculate_areas(y_pred_binary, pixel_size_mm)\n",
    "    areas_gt = calculate_areas(y_val, pixel_size_mm)\n",
    "\n",
    "    # Calculate Mean Absolute Error (MAE) for each slice\n",
    "    mae_per_slice = np.abs(areas_gt - areas_pred)\n",
    "    mae_per_slice_all_models.append(mae_per_slice)\n",
    "\n",
    "# Get the MAE values for each model\n",
    "mae_unet, mae_attention_unet, mae_multiresunet = mae_per_slice_all_models\n",
    "\n",
    "# Identify the indices where MultiResUNet performed better than Attention U-Net, and Attention U-Net performed better than U-Net\n",
    "better_indices = np.where((mae_multiresunet < mae_attention_unet) & (mae_attention_unet < mae_unet))[0]\n",
    "\n",
    "# From these indices, find the one with the smallest average MAE\n",
    "average_mae_at_better_indices = np.mean(np.array(mae_per_slice_all_models)[:, better_indices], axis=0)\n",
    "best_slice_index = better_indices[np.argmin(average_mae_at_better_indices)]\n",
    "\n",
    "\n",
    "# Visualize the best predicted slice with cross-sectional area for all models\n",
    "fig, axes = plt.subplots(len(model_filenames), 3, figsize=(15, 5 * len(model_filenames)))\n",
    "\n",
    "for i, model_filename in enumerate(model_filenames):\n",
    "    model = tf.keras.models.load_model(model_filename, custom_objects={'_weighted_binary_crossentropy': weighted_binary_crossentropy(pos_weight, neg_weight)})\n",
    "    y_pred = model.predict(x_val)\n",
    "    y_pred_binary = np.where(y_pred > 0.5, 1, 0)\n",
    "\n",
    "    predicted_area = calculate_area(y_pred_binary[best_slice_index, :, :, 0], pixel_size_mm)\n",
    "    gt_area = calculate_area(y_val[best_slice_index, :, :, 0], pixel_size_mm)\n",
    "    axes[i, 0].imshow(x_val[best_slice_index, :, :, 0], cmap='gray')\n",
    "    axes[i, 0].set_title(f\"Input image\\n{model_names[i]}\")  # use model names here\n",
    "    axes[i, 1].imshow(y_val[best_slice_index, :, :, 0], cmap='gray')\n",
    "    axes[i, 1].set_title(f\"Ground truth\\nArea: {gt_area:.2f} mm²\")\n",
    "    axes[i, 2].imshow(y_pred_binary[best_slice_index, :, :, 0], cmap='gray')\n",
    "    axes[i, 2].set_title(f\"Predicted segmentation\\nArea: {predicted_area:.2f} mm²\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
